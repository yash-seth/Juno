{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Pass Ratio</th>\n",
       "      <th>Resource Materials</th>\n",
       "      <th>Subject Knowledge</th>\n",
       "      <th>Audibility</th>\n",
       "      <th>Teaching Methods</th>\n",
       "      <th>Question Paper</th>\n",
       "      <th>Syllabus Completion</th>\n",
       "      <th>Assignments</th>\n",
       "      <th>Oppurtunities</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Guidance</th>\n",
       "      <th>Seminar</th>\n",
       "      <th>IV</th>\n",
       "      <th>Club Contribution</th>\n",
       "      <th>Guest Lecture</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.55</td>\n",
       "      <td>48.07</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.42</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.43</td>\n",
       "      <td>43.58</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.34</td>\n",
       "      <td>4.49</td>\n",
       "      <td>3.79</td>\n",
       "      <td>49.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.40</td>\n",
       "      <td>43.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.85</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.01</td>\n",
       "      <td>47.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.50</td>\n",
       "      <td>40.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>40.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.32</td>\n",
       "      <td>48.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.79</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.36</td>\n",
       "      <td>47.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA  Marks  Pass Ratio  Resource Materials  Subject Knowledge  Audibility  \\\n",
       "0  6.55  48.07        0.64                0.26               3.14        3.11   \n",
       "1  6.43  43.58        0.90                0.46               3.24        3.93   \n",
       "2  6.40  43.28        0.19                0.27               3.35        3.32   \n",
       "3  6.50  40.45        0.50                0.21               3.31        3.99   \n",
       "4  6.32  48.16        0.08                0.62               3.21        3.75   \n",
       "\n",
       "   Teaching Methods  Question Paper  Syllabus Completion  Assignments  \\\n",
       "0              0.31            1.92                 3.56         2.50   \n",
       "1              1.11            1.60                 4.02         2.13   \n",
       "2              1.79            0.30                 4.85         2.22   \n",
       "3              1.63            0.91                 3.35         1.96   \n",
       "4              1.22            0.61                 3.35         2.30   \n",
       "\n",
       "   Oppurtunities  Presentation  Publication  Guidance  Seminar    IV  \\\n",
       "0           0.67          0.31         1.41      1.15     3.12  3.42   \n",
       "1           0.08          0.38         0.95      1.24     3.08  2.34   \n",
       "2           0.61          0.01         0.29      1.65     4.79  2.11   \n",
       "3           0.86          0.67         1.71      1.77     3.24  3.95   \n",
       "4           0.50          0.98         1.42      1.79     4.84  3.21   \n",
       "\n",
       "   Club Contribution  Guest Lecture  Ratings  \n",
       "0               4.46           3.93    44.61  \n",
       "1               4.49           3.79    49.22  \n",
       "2               3.28           3.01    47.19  \n",
       "3               3.75           3.94    40.19  \n",
       "4               4.09           3.36    47.17  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "facultyScores = pd.read_csv(\"./facultyScores.csv\")\n",
    "facultyScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Pass Ratio</th>\n",
       "      <th>Resource Materials</th>\n",
       "      <th>Subject Knowledge</th>\n",
       "      <th>Audibility</th>\n",
       "      <th>Teaching Methods</th>\n",
       "      <th>Question Paper</th>\n",
       "      <th>Syllabus Completion</th>\n",
       "      <th>Assignments</th>\n",
       "      <th>Oppurtunities</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Guidance</th>\n",
       "      <th>Seminar</th>\n",
       "      <th>IV</th>\n",
       "      <th>Club Contribution</th>\n",
       "      <th>Guest Lecture</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.80</td>\n",
       "      <td>41.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.51</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.16</td>\n",
       "      <td>47.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.07</td>\n",
       "      <td>44.06</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.44</td>\n",
       "      <td>4.42</td>\n",
       "      <td>3.80</td>\n",
       "      <td>43.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.91</td>\n",
       "      <td>55.76</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.08</td>\n",
       "      <td>3.39</td>\n",
       "      <td>5.46</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5.44</td>\n",
       "      <td>6.30</td>\n",
       "      <td>4.56</td>\n",
       "      <td>46.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.31</td>\n",
       "      <td>56.84</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.15</td>\n",
       "      <td>6.72</td>\n",
       "      <td>4.73</td>\n",
       "      <td>49.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.41</td>\n",
       "      <td>61.71</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.38</td>\n",
       "      <td>3.49</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.26</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.03</td>\n",
       "      <td>5.05</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.01</td>\n",
       "      <td>4.84</td>\n",
       "      <td>41.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA  Marks  Pass Ratio  Resource Materials  Subject Knowledge  Audibility  \\\n",
       "0  6.80  41.17        0.06                0.27               3.30        3.30   \n",
       "1  6.07  44.06        1.66                1.60               3.44        3.79   \n",
       "2  6.91  55.76        5.59                5.08               3.39        5.46   \n",
       "3  6.31  56.84        5.93                5.12               3.66        4.05   \n",
       "4  6.41  61.71        5.21                5.38               3.49        6.84   \n",
       "\n",
       "   Teaching Methods  Question Paper  Syllabus Completion  Assignments  \\\n",
       "0              1.81            1.83                 3.49         1.48   \n",
       "1              1.76            1.51                 3.26         1.32   \n",
       "2              3.94            3.88                 3.17         3.92   \n",
       "3              3.26            3.40                 3.45         4.51   \n",
       "4              4.52            2.26                 4.95         4.03   \n",
       "\n",
       "   Oppurtunities  Presentation  Publication  Guidance  Seminar    IV  \\\n",
       "0           0.17          0.11         0.98      1.62     4.11  2.51   \n",
       "1           3.71          2.22         0.05      1.46     3.76  3.44   \n",
       "2           2.03          2.27         0.69      1.78     4.27  5.44   \n",
       "3           2.22          3.16         1.51      1.59     3.40  4.15   \n",
       "4           5.05          6.85         1.57      1.70     3.75  5.90   \n",
       "\n",
       "   Club Contribution  Guest Lecture  Ratings  \n",
       "0               4.75           3.16    47.11  \n",
       "1               4.42           3.80    43.97  \n",
       "2               6.30           4.56    46.52  \n",
       "3               6.72           4.73    49.27  \n",
       "4               6.01           4.84    41.29  "
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facultyScoresTest = pd.read_csv(\"./facultyScores_test.csv\")\n",
    "facultyScoresTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CGPA', 'Marks', 'Pass Ratio', 'Resource Materials',\n",
       "       'Subject Knowledge', 'Audibility', 'Teaching Methods', 'Question Paper',\n",
       "       'Syllabus Completion', 'Assignments', 'Oppurtunities', 'Presentation',\n",
       "       'Publication', 'Guidance', 'Seminar', 'IV', 'Club Contribution',\n",
       "       'Guest Lecture', 'Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facultyScores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 19)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facultyScores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = facultyScores.iloc[:, 0:18].values\n",
    "y = facultyScores.iloc[:, 18].values\n",
    "X_test = facultyScoresTest.iloc[:, 0:18].values\n",
    "y_test = facultyScoresTest.iloc[:, 18].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 18)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler()\n",
    "  \n",
    "# X = sc.fit_transform(X)\n",
    "# X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "  \n",
    "# pca = PCA(n_components = 5)\n",
    "  \n",
    "# X = pca.fit_transform(X)\n",
    "# X_test = pca.transform(X_test)\n",
    "  \n",
    "# explained_variance = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA().fit(X)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.55 48.07  0.64 ...  3.42  4.46  3.93]\n",
      " [ 6.43 43.58  0.9  ...  2.34  4.49  3.79]\n",
      " [ 6.4  43.28  0.19 ...  2.11  3.28  3.01]\n",
      " ...\n",
      " [ 9.03 92.95  9.32 ...  9.15  9.01  9.05]\n",
      " [ 9.07 92.59  9.34 ...  9.03  9.04  9.3 ]\n",
      " [ 9.02 92.78  9.25 ...  9.03  9.49  9.1 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.800e+00 4.117e+01 6.000e-02 2.700e-01 3.300e+00 3.300e+00 1.810e+00\n",
      "  1.830e+00 3.490e+00 1.480e+00 1.700e-01 1.100e-01 9.800e-01 1.620e+00\n",
      "  4.110e+00 2.510e+00 4.750e+00 3.160e+00]\n",
      " [6.070e+00 4.406e+01 1.660e+00 1.600e+00 3.440e+00 3.790e+00 1.760e+00\n",
      "  1.510e+00 3.260e+00 1.320e+00 3.710e+00 2.220e+00 5.000e-02 1.460e+00\n",
      "  3.760e+00 3.440e+00 4.420e+00 3.800e+00]\n",
      " [6.910e+00 5.576e+01 5.590e+00 5.080e+00 3.390e+00 5.460e+00 3.940e+00\n",
      "  3.880e+00 3.170e+00 3.920e+00 2.030e+00 2.270e+00 6.900e-01 1.780e+00\n",
      "  4.270e+00 5.440e+00 6.300e+00 4.560e+00]\n",
      " [6.310e+00 5.684e+01 5.930e+00 5.120e+00 3.660e+00 4.050e+00 3.260e+00\n",
      "  3.400e+00 3.450e+00 4.510e+00 2.220e+00 3.160e+00 1.510e+00 1.590e+00\n",
      "  3.400e+00 4.150e+00 6.720e+00 4.730e+00]\n",
      " [6.410e+00 6.171e+01 5.210e+00 5.380e+00 3.490e+00 6.840e+00 4.520e+00\n",
      "  2.260e+00 4.950e+00 4.030e+00 5.050e+00 6.850e+00 1.570e+00 1.700e+00\n",
      "  3.750e+00 5.900e+00 6.010e+00 4.840e+00]\n",
      " [7.420e+00 6.149e+01 6.190e+00 5.940e+00 6.180e+00 6.450e+00 4.920e+00\n",
      "  2.760e+00 5.380e+00 4.580e+00 6.340e+00 6.160e+00 2.320e+00 3.070e+00\n",
      "  3.280e+00 5.470e+00 6.130e+00 4.670e+00]\n",
      " [7.560e+00 6.590e+01 6.380e+00 6.160e+00 6.530e+00 6.390e+00 4.100e+00\n",
      "  2.850e+00 5.700e+00 4.630e+00 6.730e+00 5.090e+00 2.770e+00 2.610e+00\n",
      "  3.790e+00 5.120e+00 6.830e+00 4.530e+00]\n",
      " [7.810e+00 6.236e+01 6.470e+00 6.430e+00 5.820e+00 6.200e+00 5.980e+00\n",
      "  2.690e+00 6.450e+00 6.740e+00 6.520e+00 5.690e+00 2.800e+00 2.840e+00\n",
      "  3.140e+00 5.090e+00 6.220e+00 6.770e+00]\n",
      " [7.360e+00 6.239e+01 6.000e+00 5.970e+00 5.150e+00 6.090e+00 5.310e+00\n",
      "  2.450e+00 5.490e+00 5.530e+00 5.820e+00 5.980e+00 3.410e+00 2.920e+00\n",
      "  4.860e+00 5.140e+00 6.620e+00 6.190e+00]\n",
      " [7.710e+00 7.099e+01 5.700e+00 6.470e+00 5.860e+00 7.250e+00 6.750e+00\n",
      "  5.040e+00 5.900e+00 6.170e+00 5.030e+00 6.650e+00 2.240e+00 2.320e+00\n",
      "  4.890e+00 6.240e+00 6.550e+00 6.730e+00]\n",
      " [7.200e+00 7.218e+01 6.190e+00 5.580e+00 6.210e+00 7.270e+00 6.840e+00\n",
      "  5.330e+00 6.400e+00 6.130e+00 6.360e+00 5.830e+00 3.180e+00 2.420e+00\n",
      "  5.770e+00 6.920e+00 6.810e+00 6.940e+00]\n",
      " [7.730e+00 7.419e+01 5.800e+00 5.550e+00 5.040e+00 7.660e+00 6.650e+00\n",
      "  5.860e+00 5.670e+00 6.110e+00 6.730e+00 6.140e+00 2.550e+00 2.840e+00\n",
      "  6.510e+00 7.940e+00 6.410e+00 6.480e+00]\n",
      " [7.060e+00 7.149e+01 6.070e+00 6.730e+00 6.370e+00 7.380e+00 6.130e+00\n",
      "  4.550e+00 6.350e+00 5.850e+00 6.740e+00 5.330e+00 2.760e+00 3.210e+00\n",
      "  5.060e+00 6.480e+00 6.690e+00 6.890e+00]\n",
      " [7.420e+00 7.881e+01 5.650e+00 5.850e+00 6.220e+00 7.720e+00 6.360e+00\n",
      "  4.560e+00 6.960e+00 5.910e+00 5.910e+00 6.380e+00 2.080e+00 3.530e+00\n",
      "  5.910e+00 7.200e+00 6.410e+00 6.320e+00]\n",
      " [7.410e+00 7.217e+01 8.950e+00 8.670e+00 5.240e+00 7.820e+00 6.780e+00\n",
      "  5.120e+00 5.770e+00 6.720e+00 5.650e+00 5.870e+00 3.600e+00 3.020e+00\n",
      "  5.170e+00 7.850e+00 8.190e+00 6.430e+00]\n",
      " [7.680e+00 7.884e+01 8.380e+00 7.090e+00 5.440e+00 7.470e+00 6.440e+00\n",
      "  4.840e+00 7.210e+00 5.700e+00 5.580e+00 6.690e+00 4.320e+00 4.830e+00\n",
      "  6.310e+00 7.050e+00 8.330e+00 6.240e+00]\n",
      " [7.950e+00 7.759e+01 7.720e+00 8.050e+00 6.370e+00 7.610e+00 6.640e+00\n",
      "  5.610e+00 7.530e+00 5.400e+00 6.910e+00 6.260e+00 5.160e+00 5.350e+00\n",
      "  6.310e+00 6.730e+00 8.160e+00 6.260e+00]\n",
      " [7.190e+00 7.800e+01 8.290e+00 7.090e+00 5.070e+00 7.310e+00 6.430e+00\n",
      "  5.570e+00 8.270e+00 5.640e+00 6.220e+00 5.240e+00 5.150e+00 5.290e+00\n",
      "  5.030e+00 6.890e+00 8.520e+00 6.970e+00]\n",
      " [7.760e+00 7.260e+01 7.890e+00 8.300e+00 5.580e+00 7.700e+00 6.490e+00\n",
      "  4.710e+00 8.800e+00 6.510e+00 6.150e+00 6.010e+00 4.640e+00 4.920e+00\n",
      "  6.960e+00 7.040e+00 8.120e+00 6.770e+00]\n",
      " [7.420e+00 7.454e+01 8.560e+00 8.440e+00 5.290e+00 7.080e+00 7.380e+00\n",
      "  5.340e+00 8.130e+00 5.020e+00 7.460e+00 8.730e+00 4.780e+00 4.780e+00\n",
      "  5.150e+00 6.950e+00 8.530e+00 6.460e+00]\n",
      " [7.340e+00 7.898e+01 8.460e+00 7.180e+00 8.200e+00 7.450e+00 7.420e+00\n",
      "  4.210e+00 8.300e+00 5.240e+00 8.290e+00 7.900e+00 4.520e+00 4.230e+00\n",
      "  5.740e+00 6.500e+00 8.710e+00 6.310e+00]\n",
      " [7.850e+00 7.625e+01 8.820e+00 8.220e+00 8.300e+00 7.430e+00 7.710e+00\n",
      "  7.940e+00 8.270e+00 5.340e+00 7.480e+00 8.900e+00 5.000e+00 4.050e+00\n",
      "  5.520e+00 6.250e+00 8.760e+00 6.770e+00]\n",
      " [7.510e+00 7.831e+01 7.890e+00 8.900e+00 9.350e+00 7.270e+00 7.750e+00\n",
      "  6.980e+00 7.590e+00 8.820e+00 8.450e+00 8.300e+00 4.570e+00 5.820e+00\n",
      "  6.120e+00 7.560e+00 8.300e+00 8.100e+00]\n",
      " [7.970e+00 7.964e+01 7.480e+00 8.830e+00 8.710e+00 7.000e+00 7.480e+00\n",
      "  6.960e+00 7.990e+00 7.060e+00 8.460e+00 7.720e+00 4.680e+00 5.330e+00\n",
      "  5.760e+00 7.940e+00 8.940e+00 8.250e+00]\n",
      " [7.260e+00 7.019e+01 8.560e+00 8.190e+00 9.220e+00 8.750e+00 7.970e+00\n",
      "  7.760e+00 7.710e+00 8.760e+00 7.480e+00 7.870e+00 5.730e+00 4.240e+00\n",
      "  6.240e+00 7.990e+00 8.440e+00 8.920e+00]\n",
      " [7.930e+00 7.591e+01 7.570e+00 8.360e+00 8.220e+00 8.200e+00 7.100e+00\n",
      "  6.020e+00 7.320e+00 8.690e+00 8.150e+00 7.230e+00 4.840e+00 5.110e+00\n",
      "  5.590e+00 6.110e+00 8.780e+00 8.090e+00]\n",
      " [7.310e+00 7.368e+01 7.720e+00 7.880e+00 8.930e+00 8.850e+00 7.990e+00\n",
      "  6.230e+00 7.240e+00 7.600e+00 8.300e+00 7.990e+00 4.050e+00 5.900e+00\n",
      "  5.840e+00 8.870e+00 8.880e+00 8.670e+00]\n",
      " [7.950e+00 7.039e+01 8.370e+00 7.200e+00 8.940e+00 8.410e+00 7.840e+00\n",
      "  6.410e+00 7.800e+00 8.030e+00 7.500e+00 8.180e+00 4.630e+00 4.580e+00\n",
      "  5.580e+00 8.350e+00 8.990e+00 8.330e+00]\n",
      " [7.230e+00 7.367e+01 8.070e+00 8.680e+00 9.220e+00 8.890e+00 7.160e+00\n",
      "  7.710e+00 8.090e+00 8.490e+00 7.720e+00 7.210e+00 5.330e+00 4.820e+00\n",
      "  5.040e+00 8.800e+00 8.990e+00 8.540e+00]\n",
      " [7.500e+00 8.153e+01 8.780e+00 8.700e+00 8.010e+00 8.610e+00 8.170e+00\n",
      "  7.250e+00 7.730e+00 7.040e+00 7.210e+00 8.010e+00 5.520e+00 5.060e+00\n",
      "  6.400e+00 8.610e+00 8.770e+00 8.130e+00]\n",
      " [8.130e+00 8.135e+01 8.720e+00 7.780e+00 8.150e+00 8.360e+00 8.650e+00\n",
      "  6.460e+00 7.140e+00 7.640e+00 8.490e+00 8.360e+00 7.190e+00 6.660e+00\n",
      "  6.450e+00 8.060e+00 8.750e+00 8.690e+00]\n",
      " [8.920e+00 8.928e+01 7.830e+00 7.200e+00 9.180e+00 8.300e+00 8.670e+00\n",
      "  7.900e+00 8.070e+00 8.390e+00 8.380e+00 7.790e+00 6.270e+00 7.660e+00\n",
      "  6.350e+00 8.690e+00 8.240e+00 8.790e+00]\n",
      " [8.940e+00 8.304e+01 7.790e+00 8.080e+00 9.150e+00 8.530e+00 8.880e+00\n",
      "  7.550e+00 8.210e+00 8.210e+00 7.420e+00 7.650e+00 6.700e+00 6.340e+00\n",
      "  6.940e+00 8.370e+00 8.780e+00 8.560e+00]\n",
      " [8.560e+00 8.935e+01 7.320e+00 7.220e+00 8.040e+00 8.610e+00 8.230e+00\n",
      "  7.730e+00 8.170e+00 7.900e+00 8.640e+00 7.950e+00 7.510e+00 6.980e+00\n",
      "  5.640e+00 8.340e+00 8.280e+00 8.770e+00]\n",
      " [8.850e+00 8.660e+01 8.520e+00 8.310e+00 9.370e+00 8.000e+00 8.070e+00\n",
      "  6.890e+00 8.000e+00 8.410e+00 7.650e+00 8.200e+00 6.770e+00 6.220e+00\n",
      "  6.920e+00 8.350e+00 8.390e+00 8.430e+00]\n",
      " [8.260e+00 8.422e+01 7.980e+00 8.060e+00 8.310e+00 8.490e+00 8.120e+00\n",
      "  7.570e+00 9.160e+00 8.020e+00 7.670e+00 8.520e+00 6.670e+00 6.950e+00\n",
      "  7.430e+00 8.140e+00 8.940e+00 8.980e+00]\n",
      " [8.840e+00 8.784e+01 7.220e+00 7.940e+00 8.340e+00 8.210e+00 8.840e+00\n",
      "  7.550e+00 9.220e+00 7.850e+00 8.810e+00 8.770e+00 7.110e+00 6.520e+00\n",
      "  8.040e+00 8.870e+00 8.080e+00 8.420e+00]\n",
      " [8.720e+00 8.601e+01 7.980e+00 8.800e+00 8.220e+00 8.360e+00 8.990e+00\n",
      "  6.930e+00 9.500e+00 8.750e+00 7.430e+00 8.220e+00 6.590e+00 7.860e+00\n",
      "  7.430e+00 8.260e+00 8.940e+00 8.510e+00]\n",
      " [8.200e+00 8.643e+01 7.930e+00 8.340e+00 8.010e+00 8.700e+00 8.670e+00\n",
      "  9.130e+00 9.230e+00 8.670e+00 8.890e+00 7.360e+00 7.670e+00 6.960e+00\n",
      "  8.360e+00 8.350e+00 8.990e+00 8.660e+00]\n",
      " [8.120e+00 8.614e+01 7.030e+00 8.510e+00 8.580e+00 9.170e+00 8.120e+00\n",
      "  8.850e+00 9.400e+00 7.520e+00 8.730e+00 8.000e+00 6.020e+00 7.230e+00\n",
      "  7.860e+00 8.170e+00 8.800e+00 8.630e+00]\n",
      " [8.670e+00 8.546e+01 7.110e+00 7.650e+00 8.210e+00 9.100e+00 8.900e+00\n",
      "  9.270e+00 9.340e+00 8.670e+00 8.880e+00 8.820e+00 7.250e+00 6.950e+00\n",
      "  7.160e+00 8.860e+00 8.930e+00 8.830e+00]\n",
      " [8.400e+00 8.744e+01 7.660e+00 8.620e+00 9.000e+00 9.350e+00 9.060e+00\n",
      "  8.700e+00 9.350e+00 7.900e+00 8.890e+00 7.130e+00 6.160e+00 6.330e+00\n",
      "  7.840e+00 8.250e+00 9.180e+00 8.600e+00]\n",
      " [8.810e+00 8.810e+01 8.020e+00 7.350e+00 8.990e+00 9.320e+00 9.270e+00\n",
      "  8.890e+00 9.150e+00 9.340e+00 7.970e+00 7.980e+00 7.080e+00 6.460e+00\n",
      "  8.940e+00 8.190e+00 9.310e+00 9.250e+00]\n",
      " [8.580e+00 8.232e+01 7.690e+00 7.740e+00 8.820e+00 9.190e+00 9.080e+00\n",
      "  9.000e+00 9.190e+00 9.290e+00 7.870e+00 7.810e+00 6.980e+00 6.520e+00\n",
      "  7.220e+00 9.070e+00 9.200e+00 9.200e+00]\n",
      " [8.020e+00 8.947e+01 9.270e+00 9.190e+00 8.900e+00 9.380e+00 9.040e+00\n",
      "  8.320e+00 9.400e+00 9.040e+00 9.020e+00 9.320e+00 7.230e+00 7.380e+00\n",
      "  7.330e+00 9.220e+00 9.440e+00 9.250e+00]\n",
      " [8.060e+00 8.813e+01 9.220e+00 9.120e+00 8.540e+00 9.180e+00 9.010e+00\n",
      "  9.200e+00 9.230e+00 9.440e+00 9.200e+00 9.400e+00 9.000e+00 8.950e+00\n",
      "  7.040e+00 9.270e+00 9.250e+00 9.270e+00]\n",
      " [8.860e+00 9.206e+01 9.210e+00 9.010e+00 8.430e+00 9.400e+00 9.090e+00\n",
      "  9.260e+00 9.490e+00 9.220e+00 9.320e+00 9.150e+00 8.060e+00 8.310e+00\n",
      "  8.390e+00 9.160e+00 9.480e+00 9.220e+00]\n",
      " [9.110e+00 9.108e+01 9.300e+00 9.310e+00 8.460e+00 9.240e+00 9.180e+00\n",
      "  8.110e+00 9.350e+00 9.260e+00 9.290e+00 9.330e+00 8.930e+00 8.020e+00\n",
      "  7.560e+00 9.110e+00 9.210e+00 9.250e+00]\n",
      " [9.110e+00 9.122e+01 9.120e+00 9.040e+00 8.290e+00 9.250e+00 9.070e+00\n",
      "  8.500e+00 9.150e+00 9.360e+00 9.290e+00 9.190e+00 8.270e+00 8.020e+00\n",
      "  7.510e+00 9.300e+00 9.090e+00 9.270e+00]\n",
      " [9.120e+00 9.091e+01 9.040e+00 9.030e+00 8.560e+00 9.310e+00 9.220e+00\n",
      "  8.010e+00 9.410e+00 9.280e+00 9.260e+00 9.250e+00 8.240e+00 8.700e+00\n",
      "  8.260e+00 9.070e+00 9.460e+00 9.090e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.931 44.179 46.883 47.083 50.36  51.434 54.006 53.058 52.757 59.558\n",
      " 61.433 63.295 60.434 66.89  62.233 68.855 68.746 68.527 64.33  65.999\n",
      " 69.757 68.723 72.489 72.972 65.653 68.941 67.945 64.748 68.275 75.439\n",
      " 76.848 85.167 78.821 84.819 81.96  80.333 84.165 82.572 83.758 82.42\n",
      " 82.884 83.701 85.53  79.687 87.543 87.826 91.182 90.104 89.969 90.03 ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "print(y_pred.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.93065081 47.11      ]\n",
      " [44.17926699 43.97      ]\n",
      " [46.88296849 46.52      ]\n",
      " [47.08278891 49.27      ]\n",
      " [50.36025633 41.29      ]\n",
      " [51.43378649 42.05      ]\n",
      " [54.00615234 40.85      ]\n",
      " [53.05778753 57.93      ]\n",
      " [52.75704487 67.46      ]\n",
      " [59.55790947 53.43      ]\n",
      " [61.43278445 58.84      ]\n",
      " [63.29489148 65.96      ]\n",
      " [60.43357994 69.14      ]\n",
      " [66.88971356 54.48      ]\n",
      " [62.23298565 68.82      ]\n",
      " [68.85457021 57.16      ]\n",
      " [68.74630605 72.22      ]\n",
      " [68.52742003 55.41      ]\n",
      " [64.33005327 64.9       ]\n",
      " [65.99915206 62.66      ]\n",
      " [69.75677559 58.61      ]\n",
      " [68.7233786  56.46      ]\n",
      " [72.48888298 67.8       ]\n",
      " [72.97202543 53.7       ]\n",
      " [65.65340855 57.98      ]\n",
      " [68.94078562 62.08      ]\n",
      " [67.9446377  74.64      ]\n",
      " [64.74750712 67.66      ]\n",
      " [68.27539479 65.46      ]\n",
      " [75.43890685 78.69      ]\n",
      " [76.84768082 80.41      ]\n",
      " [85.16700297 79.92      ]\n",
      " [78.82078348 79.32      ]\n",
      " [84.81906588 82.55      ]\n",
      " [81.96023557 76.69      ]\n",
      " [80.33332279 89.78      ]\n",
      " [84.16549524 78.79      ]\n",
      " [82.57188131 79.39      ]\n",
      " [83.7581037  80.79      ]\n",
      " [82.42008892 85.47      ]\n",
      " [82.88444409 83.37      ]\n",
      " [83.70116836 75.75      ]\n",
      " [85.53023251 81.21      ]\n",
      " [79.68667605 89.7       ]\n",
      " [87.54298927 94.39      ]\n",
      " [87.82585663 94.97      ]\n",
      " [91.18165506 93.3       ]\n",
      " [90.10422017 94.89      ]\n",
      " [89.96865475 93.8       ]\n",
      " [90.02959635 92.44      ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7866388260289734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# accuracy_score(y_test, y_pred)\n",
    "print(regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.27148291027197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=7, random_state=0)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(max_depth=7, random_state=0)\n",
    "RFR.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.41718088 47.11      ]\n",
      " [45.59713328 43.97      ]\n",
      " [45.73821988 46.52      ]\n",
      " [45.74268227 49.27      ]\n",
      " [45.64075718 41.29      ]\n",
      " [45.55203631 42.05      ]\n",
      " [45.33289063 40.85      ]\n",
      " [63.02136125 57.93      ]\n",
      " [63.49227592 67.46      ]\n",
      " [61.63012657 53.43      ]\n",
      " [63.27419462 58.84      ]\n",
      " [61.18539517 65.96      ]\n",
      " [62.54533398 69.14      ]\n",
      " [61.86270881 54.48      ]\n",
      " [62.35607037 68.82      ]\n",
      " [62.13410832 57.16      ]\n",
      " [62.40113687 72.22      ]\n",
      " [62.14422935 55.41      ]\n",
      " [62.76945141 64.9       ]\n",
      " [62.51428461 62.66      ]\n",
      " [62.17493068 58.61      ]\n",
      " [62.43420498 56.46      ]\n",
      " [62.7674695  67.8       ]\n",
      " [62.27711357 53.7       ]\n",
      " [62.68758256 57.98      ]\n",
      " [61.9765865  62.08      ]\n",
      " [62.83752547 74.64      ]\n",
      " [62.90321534 67.66      ]\n",
      " [63.06138603 65.46      ]\n",
      " [73.22269605 78.69      ]\n",
      " [83.36259546 80.41      ]\n",
      " [83.08674833 79.92      ]\n",
      " [81.79522778 79.32      ]\n",
      " [83.72328074 82.55      ]\n",
      " [81.61247388 76.69      ]\n",
      " [82.34810663 89.78      ]\n",
      " [82.39806567 78.79      ]\n",
      " [82.06519284 79.39      ]\n",
      " [82.60709692 80.79      ]\n",
      " [83.33445228 85.47      ]\n",
      " [82.90906211 83.37      ]\n",
      " [83.26036407 75.75      ]\n",
      " [82.56779197 81.21      ]\n",
      " [82.6314023  89.7       ]\n",
      " [87.73430694 94.39      ]\n",
      " [92.62231811 94.97      ]\n",
      " [92.65375427 93.3       ]\n",
      " [92.78882182 94.89      ]\n",
      " [92.97589819 93.8       ]\n",
      " [92.11046296 92.44      ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = RFR.predict(X_test)\n",
    "y_actual = np.array(y_test)\n",
    "\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_actual.reshape(len(y_actual), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9043922142426708"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "RFR.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9034203160469052"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy\n",
    "RFR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8922448141404\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 2 faculty scores - in same slot course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score of Faculty #47: 92.78882182286246 \n",
      "Predicted Score of Faculty #17: 62.14422935278153\n",
      "Faculty #47 is better than Faculty #17\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Score of Faculty #47:\", y_pred[47], \"\\nPredicted Score of Faculty #17:\", y_pred[17], sep=\" \")\n",
    "if y_pred[47] > y_pred[17]:\n",
    "    print(\"Faculty #47 is better than Faculty #17\")\n",
    "else:\n",
    "    print(\"Faculty #17 is better than Faculty #47\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
