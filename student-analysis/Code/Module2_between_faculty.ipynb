{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Pass Ratio</th>\n",
       "      <th>Resource Materials</th>\n",
       "      <th>Subject Knowledge</th>\n",
       "      <th>Audibility</th>\n",
       "      <th>Teaching Methods</th>\n",
       "      <th>Question Paper</th>\n",
       "      <th>Syllabus Completion</th>\n",
       "      <th>Assignments</th>\n",
       "      <th>Oppurtunities</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Guidance</th>\n",
       "      <th>Seminar</th>\n",
       "      <th>IV</th>\n",
       "      <th>Club Contribution</th>\n",
       "      <th>Guest Lecture</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.55</td>\n",
       "      <td>48.07</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.14</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.42</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.93</td>\n",
       "      <td>44.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.43</td>\n",
       "      <td>43.58</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.46</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.34</td>\n",
       "      <td>4.49</td>\n",
       "      <td>3.79</td>\n",
       "      <td>49.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.40</td>\n",
       "      <td>43.28</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.85</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.01</td>\n",
       "      <td>47.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.50</td>\n",
       "      <td>40.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>40.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.32</td>\n",
       "      <td>48.16</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.62</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.79</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.21</td>\n",
       "      <td>4.09</td>\n",
       "      <td>3.36</td>\n",
       "      <td>47.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA  Marks  Pass Ratio  Resource Materials  Subject Knowledge  Audibility  \\\n",
       "0  6.55  48.07        0.64                0.26               3.14        3.11   \n",
       "1  6.43  43.58        0.90                0.46               3.24        3.93   \n",
       "2  6.40  43.28        0.19                0.27               3.35        3.32   \n",
       "3  6.50  40.45        0.50                0.21               3.31        3.99   \n",
       "4  6.32  48.16        0.08                0.62               3.21        3.75   \n",
       "\n",
       "   Teaching Methods  Question Paper  Syllabus Completion  Assignments  \\\n",
       "0              0.31            1.92                 3.56         2.50   \n",
       "1              1.11            1.60                 4.02         2.13   \n",
       "2              1.79            0.30                 4.85         2.22   \n",
       "3              1.63            0.91                 3.35         1.96   \n",
       "4              1.22            0.61                 3.35         2.30   \n",
       "\n",
       "   Oppurtunities  Presentation  Publication  Guidance  Seminar    IV  \\\n",
       "0           0.67          0.31         1.41      1.15     3.12  3.42   \n",
       "1           0.08          0.38         0.95      1.24     3.08  2.34   \n",
       "2           0.61          0.01         0.29      1.65     4.79  2.11   \n",
       "3           0.86          0.67         1.71      1.77     3.24  3.95   \n",
       "4           0.50          0.98         1.42      1.79     4.84  3.21   \n",
       "\n",
       "   Club Contribution  Guest Lecture  Ratings  \n",
       "0               4.46           3.93    44.61  \n",
       "1               4.49           3.79    49.22  \n",
       "2               3.28           3.01    47.19  \n",
       "3               3.75           3.94    40.19  \n",
       "4               4.09           3.36    47.17  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "facultyScores = pd.read_csv(\"./facultyScores.csv\")\n",
    "facultyScores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Pass Ratio</th>\n",
       "      <th>Resource Materials</th>\n",
       "      <th>Subject Knowledge</th>\n",
       "      <th>Audibility</th>\n",
       "      <th>Teaching Methods</th>\n",
       "      <th>Question Paper</th>\n",
       "      <th>Syllabus Completion</th>\n",
       "      <th>Assignments</th>\n",
       "      <th>Oppurtunities</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Guidance</th>\n",
       "      <th>Seminar</th>\n",
       "      <th>IV</th>\n",
       "      <th>Club Contribution</th>\n",
       "      <th>Guest Lecture</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.80</td>\n",
       "      <td>41.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.62</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2.51</td>\n",
       "      <td>4.75</td>\n",
       "      <td>3.16</td>\n",
       "      <td>47.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.07</td>\n",
       "      <td>44.06</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.60</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.79</td>\n",
       "      <td>1.76</td>\n",
       "      <td>1.51</td>\n",
       "      <td>3.26</td>\n",
       "      <td>1.32</td>\n",
       "      <td>3.71</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.46</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.44</td>\n",
       "      <td>4.42</td>\n",
       "      <td>3.80</td>\n",
       "      <td>43.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.91</td>\n",
       "      <td>55.76</td>\n",
       "      <td>5.59</td>\n",
       "      <td>5.08</td>\n",
       "      <td>3.39</td>\n",
       "      <td>5.46</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.88</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.03</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1.78</td>\n",
       "      <td>4.27</td>\n",
       "      <td>5.44</td>\n",
       "      <td>6.30</td>\n",
       "      <td>4.56</td>\n",
       "      <td>46.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.31</td>\n",
       "      <td>56.84</td>\n",
       "      <td>5.93</td>\n",
       "      <td>5.12</td>\n",
       "      <td>3.66</td>\n",
       "      <td>4.05</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.40</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4.51</td>\n",
       "      <td>2.22</td>\n",
       "      <td>3.16</td>\n",
       "      <td>1.51</td>\n",
       "      <td>1.59</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.15</td>\n",
       "      <td>6.72</td>\n",
       "      <td>4.73</td>\n",
       "      <td>49.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.41</td>\n",
       "      <td>61.71</td>\n",
       "      <td>5.21</td>\n",
       "      <td>5.38</td>\n",
       "      <td>3.49</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.52</td>\n",
       "      <td>2.26</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.03</td>\n",
       "      <td>5.05</td>\n",
       "      <td>6.85</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.70</td>\n",
       "      <td>3.75</td>\n",
       "      <td>5.90</td>\n",
       "      <td>6.01</td>\n",
       "      <td>4.84</td>\n",
       "      <td>41.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA  Marks  Pass Ratio  Resource Materials  Subject Knowledge  Audibility  \\\n",
       "0  6.80  41.17        0.06                0.27               3.30        3.30   \n",
       "1  6.07  44.06        1.66                1.60               3.44        3.79   \n",
       "2  6.91  55.76        5.59                5.08               3.39        5.46   \n",
       "3  6.31  56.84        5.93                5.12               3.66        4.05   \n",
       "4  6.41  61.71        5.21                5.38               3.49        6.84   \n",
       "\n",
       "   Teaching Methods  Question Paper  Syllabus Completion  Assignments  \\\n",
       "0              1.81            1.83                 3.49         1.48   \n",
       "1              1.76            1.51                 3.26         1.32   \n",
       "2              3.94            3.88                 3.17         3.92   \n",
       "3              3.26            3.40                 3.45         4.51   \n",
       "4              4.52            2.26                 4.95         4.03   \n",
       "\n",
       "   Oppurtunities  Presentation  Publication  Guidance  Seminar    IV  \\\n",
       "0           0.17          0.11         0.98      1.62     4.11  2.51   \n",
       "1           3.71          2.22         0.05      1.46     3.76  3.44   \n",
       "2           2.03          2.27         0.69      1.78     4.27  5.44   \n",
       "3           2.22          3.16         1.51      1.59     3.40  4.15   \n",
       "4           5.05          6.85         1.57      1.70     3.75  5.90   \n",
       "\n",
       "   Club Contribution  Guest Lecture  Ratings  \n",
       "0               4.75           3.16    47.11  \n",
       "1               4.42           3.80    43.97  \n",
       "2               6.30           4.56    46.52  \n",
       "3               6.72           4.73    49.27  \n",
       "4               6.01           4.84    41.29  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facultyScoresTest = pd.read_csv(\"./facultyScores_test.csv\")\n",
    "facultyScoresTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CGPA', 'Marks', 'Pass Ratio', 'Resource Materials',\n",
       "       'Subject Knowledge', 'Audibility', 'Teaching Methods', 'Question Paper',\n",
       "       'Syllabus Completion', 'Assignments', 'Oppurtunities', 'Presentation',\n",
       "       'Publication', 'Guidance', 'Seminar', 'IV', 'Club Contribution',\n",
       "       'Guest Lecture', 'Ratings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facultyScores.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 19)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facultyScores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = facultyScores.drop(['Club Contribution'], axis = 1)\n",
    "# y = facultyScoresTest.drop(['Club Contribution'], axis = 1)\n",
    "X = facultyScores[['CGPA', 'Marks', 'Pass Ratio', 'Resource Materials',\n",
    "       'Subject Knowledge', 'Audibility', 'Teaching Methods', 'Question Paper',\n",
    "       'Syllabus Completion', 'Assignments']]\n",
    "# print(X.columns)\n",
    "\n",
    "X_test = facultyScoresTest[['CGPA', 'Marks', 'Pass Ratio', 'Resource Materials',\n",
    "       'Subject Knowledge', 'Audibility', 'Teaching Methods', 'Question Paper',\n",
    "       'Syllabus Completion', 'Assignments']]\n",
    "\n",
    "# print(X_test.columns)\n",
    "\n",
    "# X = facultyScores.drop([\"Ratings\", \"Club Contribution\"], axis = 1)\n",
    "y = facultyScores[['Ratings']]\n",
    "# X_test = facultyScoresTest.drop([\"Ratings\" , \"Club Contribution\"], axis = 1)\n",
    "y_test = facultyScoresTest[['Ratings']]\n",
    "# print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Marks', 'Teaching Methods', 'Publication', 'Guidance',\n",
      "       'Guest Lecture'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "# # Create and fit selector\n",
    "# selector = SelectKBest(f_classif, k=5)\n",
    "# selector.fit(X, y)\n",
    "# # Get columns to keep and create new dataframe with those only\n",
    "# cols_idxs = selector.get_support(indices=True)\n",
    "# X_new_train = X.iloc[:,cols_idxs]\n",
    "# X_new_test = X_test.iloc[:,cols_idxs]\n",
    "# print(X_new_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Marks</th>\n",
       "      <th>Audibility</th>\n",
       "      <th>Teaching Methods</th>\n",
       "      <th>Question Paper</th>\n",
       "      <th>Syllabus Completion</th>\n",
       "      <th>Assignments</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Guidance</th>\n",
       "      <th>Seminar</th>\n",
       "      <th>IV</th>\n",
       "      <th>Guest Lecture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.55</td>\n",
       "      <td>48.07</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.56</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.43</td>\n",
       "      <td>43.58</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1.11</td>\n",
       "      <td>1.60</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.34</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.40</td>\n",
       "      <td>43.28</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.30</td>\n",
       "      <td>4.85</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4.79</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.50</td>\n",
       "      <td>40.45</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.77</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.32</td>\n",
       "      <td>48.16</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.42</td>\n",
       "      <td>1.79</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CGPA  Marks  Audibility  Teaching Methods  Question Paper  \\\n",
       "0  6.55  48.07        3.11              0.31            1.92   \n",
       "1  6.43  43.58        3.93              1.11            1.60   \n",
       "2  6.40  43.28        3.32              1.79            0.30   \n",
       "3  6.50  40.45        3.99              1.63            0.91   \n",
       "4  6.32  48.16        3.75              1.22            0.61   \n",
       "\n",
       "   Syllabus Completion  Assignments  Publication  Guidance  Seminar    IV  \\\n",
       "0                 3.56         2.50         1.41      1.15     3.12  3.42   \n",
       "1                 4.02         2.13         0.95      1.24     3.08  2.34   \n",
       "2                 4.85         2.22         0.29      1.65     4.79  2.11   \n",
       "3                 3.35         1.96         1.71      1.77     3.24  3.95   \n",
       "4                 3.35         2.30         1.42      1.79     4.84  3.21   \n",
       "\n",
       "   Guest Lecture  \n",
       "0           3.93  \n",
       "1           3.79  \n",
       "2           3.01  \n",
       "3           3.94  \n",
       "4           3.36  "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X = X_new_train\n",
    "# X_test = X_new_test\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 10)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 1)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.38877106 -3.03312638 -4.23276082 -4.03907052 -2.2121188  -3.0117624\n",
      " -2.49364628 -1.83411428 -2.38269883 -2.75965336]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "  \n",
    "X = sc.fit_transform(X)\n",
    "X_test = sc.transform(X_test)\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.43895916  2.43056897 -1.07388063 -0.3325453   0.05947834]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# import matplotlib.pyplot as plt\n",
    "  \n",
    "# pca = PCA(n_components = 5)\n",
    "  \n",
    "# X = pca.fit_transform(X)\n",
    "# X_test = pca.transform(X_test)\n",
    "  \n",
    "# explained_variance = pca.explained_variance_ratio_\n",
    "# print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'cumulative explained variance')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# pca = PCA().fit(X)\n",
    "# plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "# plt.xlabel('number of components')\n",
    "# plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.43895916  2.43056897 -1.07388063 -0.3325453   0.05947834]\n",
      " [10.56146383  2.18074093 -1.02287427 -0.29730679 -0.32846599]\n",
      " [10.63273929  2.83929589 -0.86385227 -0.34421396 -1.2463716 ]\n",
      " ...\n",
      " [-4.76913342  0.23268701  0.18433278  0.71309398  0.49473063]\n",
      " [-4.72059792  0.42361201  0.44905249  0.62531856  0.47617672]\n",
      " [-4.75189747  0.34487791  0.03628111  0.55338774  0.34338381]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.800e+00 4.117e+01 6.000e-02 2.700e-01 3.300e+00 3.300e+00 1.810e+00\n",
      "  1.830e+00 3.490e+00 1.480e+00 1.700e-01 1.100e-01 9.800e-01 1.620e+00\n",
      "  4.110e+00 2.510e+00 4.750e+00 3.160e+00]\n",
      " [6.070e+00 4.406e+01 1.660e+00 1.600e+00 3.440e+00 3.790e+00 1.760e+00\n",
      "  1.510e+00 3.260e+00 1.320e+00 3.710e+00 2.220e+00 5.000e-02 1.460e+00\n",
      "  3.760e+00 3.440e+00 4.420e+00 3.800e+00]\n",
      " [6.910e+00 5.576e+01 5.590e+00 5.080e+00 3.390e+00 5.460e+00 3.940e+00\n",
      "  3.880e+00 3.170e+00 3.920e+00 2.030e+00 2.270e+00 6.900e-01 1.780e+00\n",
      "  4.270e+00 5.440e+00 6.300e+00 4.560e+00]\n",
      " [6.310e+00 5.684e+01 5.930e+00 5.120e+00 3.660e+00 4.050e+00 3.260e+00\n",
      "  3.400e+00 3.450e+00 4.510e+00 2.220e+00 3.160e+00 1.510e+00 1.590e+00\n",
      "  3.400e+00 4.150e+00 6.720e+00 4.730e+00]\n",
      " [6.410e+00 6.171e+01 5.210e+00 5.380e+00 3.490e+00 6.840e+00 4.520e+00\n",
      "  2.260e+00 4.950e+00 4.030e+00 5.050e+00 6.850e+00 1.570e+00 1.700e+00\n",
      "  3.750e+00 5.900e+00 6.010e+00 4.840e+00]\n",
      " [7.420e+00 6.149e+01 6.190e+00 5.940e+00 6.180e+00 6.450e+00 4.920e+00\n",
      "  2.760e+00 5.380e+00 4.580e+00 6.340e+00 6.160e+00 2.320e+00 3.070e+00\n",
      "  3.280e+00 5.470e+00 6.130e+00 4.670e+00]\n",
      " [7.560e+00 6.590e+01 6.380e+00 6.160e+00 6.530e+00 6.390e+00 4.100e+00\n",
      "  2.850e+00 5.700e+00 4.630e+00 6.730e+00 5.090e+00 2.770e+00 2.610e+00\n",
      "  3.790e+00 5.120e+00 6.830e+00 4.530e+00]\n",
      " [7.810e+00 6.236e+01 6.470e+00 6.430e+00 5.820e+00 6.200e+00 5.980e+00\n",
      "  2.690e+00 6.450e+00 6.740e+00 6.520e+00 5.690e+00 2.800e+00 2.840e+00\n",
      "  3.140e+00 5.090e+00 6.220e+00 6.770e+00]\n",
      " [7.360e+00 6.239e+01 6.000e+00 5.970e+00 5.150e+00 6.090e+00 5.310e+00\n",
      "  2.450e+00 5.490e+00 5.530e+00 5.820e+00 5.980e+00 3.410e+00 2.920e+00\n",
      "  4.860e+00 5.140e+00 6.620e+00 6.190e+00]\n",
      " [7.710e+00 7.099e+01 5.700e+00 6.470e+00 5.860e+00 7.250e+00 6.750e+00\n",
      "  5.040e+00 5.900e+00 6.170e+00 5.030e+00 6.650e+00 2.240e+00 2.320e+00\n",
      "  4.890e+00 6.240e+00 6.550e+00 6.730e+00]\n",
      " [7.200e+00 7.218e+01 6.190e+00 5.580e+00 6.210e+00 7.270e+00 6.840e+00\n",
      "  5.330e+00 6.400e+00 6.130e+00 6.360e+00 5.830e+00 3.180e+00 2.420e+00\n",
      "  5.770e+00 6.920e+00 6.810e+00 6.940e+00]\n",
      " [7.730e+00 7.419e+01 5.800e+00 5.550e+00 5.040e+00 7.660e+00 6.650e+00\n",
      "  5.860e+00 5.670e+00 6.110e+00 6.730e+00 6.140e+00 2.550e+00 2.840e+00\n",
      "  6.510e+00 7.940e+00 6.410e+00 6.480e+00]\n",
      " [7.060e+00 7.149e+01 6.070e+00 6.730e+00 6.370e+00 7.380e+00 6.130e+00\n",
      "  4.550e+00 6.350e+00 5.850e+00 6.740e+00 5.330e+00 2.760e+00 3.210e+00\n",
      "  5.060e+00 6.480e+00 6.690e+00 6.890e+00]\n",
      " [7.420e+00 7.881e+01 5.650e+00 5.850e+00 6.220e+00 7.720e+00 6.360e+00\n",
      "  4.560e+00 6.960e+00 5.910e+00 5.910e+00 6.380e+00 2.080e+00 3.530e+00\n",
      "  5.910e+00 7.200e+00 6.410e+00 6.320e+00]\n",
      " [7.410e+00 7.217e+01 8.950e+00 8.670e+00 5.240e+00 7.820e+00 6.780e+00\n",
      "  5.120e+00 5.770e+00 6.720e+00 5.650e+00 5.870e+00 3.600e+00 3.020e+00\n",
      "  5.170e+00 7.850e+00 8.190e+00 6.430e+00]\n",
      " [7.680e+00 7.884e+01 8.380e+00 7.090e+00 5.440e+00 7.470e+00 6.440e+00\n",
      "  4.840e+00 7.210e+00 5.700e+00 5.580e+00 6.690e+00 4.320e+00 4.830e+00\n",
      "  6.310e+00 7.050e+00 8.330e+00 6.240e+00]\n",
      " [7.950e+00 7.759e+01 7.720e+00 8.050e+00 6.370e+00 7.610e+00 6.640e+00\n",
      "  5.610e+00 7.530e+00 5.400e+00 6.910e+00 6.260e+00 5.160e+00 5.350e+00\n",
      "  6.310e+00 6.730e+00 8.160e+00 6.260e+00]\n",
      " [7.190e+00 7.800e+01 8.290e+00 7.090e+00 5.070e+00 7.310e+00 6.430e+00\n",
      "  5.570e+00 8.270e+00 5.640e+00 6.220e+00 5.240e+00 5.150e+00 5.290e+00\n",
      "  5.030e+00 6.890e+00 8.520e+00 6.970e+00]\n",
      " [7.760e+00 7.260e+01 7.890e+00 8.300e+00 5.580e+00 7.700e+00 6.490e+00\n",
      "  4.710e+00 8.800e+00 6.510e+00 6.150e+00 6.010e+00 4.640e+00 4.920e+00\n",
      "  6.960e+00 7.040e+00 8.120e+00 6.770e+00]\n",
      " [7.420e+00 7.454e+01 8.560e+00 8.440e+00 5.290e+00 7.080e+00 7.380e+00\n",
      "  5.340e+00 8.130e+00 5.020e+00 7.460e+00 8.730e+00 4.780e+00 4.780e+00\n",
      "  5.150e+00 6.950e+00 8.530e+00 6.460e+00]\n",
      " [7.340e+00 7.898e+01 8.460e+00 7.180e+00 8.200e+00 7.450e+00 7.420e+00\n",
      "  4.210e+00 8.300e+00 5.240e+00 8.290e+00 7.900e+00 4.520e+00 4.230e+00\n",
      "  5.740e+00 6.500e+00 8.710e+00 6.310e+00]\n",
      " [7.850e+00 7.625e+01 8.820e+00 8.220e+00 8.300e+00 7.430e+00 7.710e+00\n",
      "  7.940e+00 8.270e+00 5.340e+00 7.480e+00 8.900e+00 5.000e+00 4.050e+00\n",
      "  5.520e+00 6.250e+00 8.760e+00 6.770e+00]\n",
      " [7.510e+00 7.831e+01 7.890e+00 8.900e+00 9.350e+00 7.270e+00 7.750e+00\n",
      "  6.980e+00 7.590e+00 8.820e+00 8.450e+00 8.300e+00 4.570e+00 5.820e+00\n",
      "  6.120e+00 7.560e+00 8.300e+00 8.100e+00]\n",
      " [7.970e+00 7.964e+01 7.480e+00 8.830e+00 8.710e+00 7.000e+00 7.480e+00\n",
      "  6.960e+00 7.990e+00 7.060e+00 8.460e+00 7.720e+00 4.680e+00 5.330e+00\n",
      "  5.760e+00 7.940e+00 8.940e+00 8.250e+00]\n",
      " [7.260e+00 7.019e+01 8.560e+00 8.190e+00 9.220e+00 8.750e+00 7.970e+00\n",
      "  7.760e+00 7.710e+00 8.760e+00 7.480e+00 7.870e+00 5.730e+00 4.240e+00\n",
      "  6.240e+00 7.990e+00 8.440e+00 8.920e+00]\n",
      " [7.930e+00 7.591e+01 7.570e+00 8.360e+00 8.220e+00 8.200e+00 7.100e+00\n",
      "  6.020e+00 7.320e+00 8.690e+00 8.150e+00 7.230e+00 4.840e+00 5.110e+00\n",
      "  5.590e+00 6.110e+00 8.780e+00 8.090e+00]\n",
      " [7.310e+00 7.368e+01 7.720e+00 7.880e+00 8.930e+00 8.850e+00 7.990e+00\n",
      "  6.230e+00 7.240e+00 7.600e+00 8.300e+00 7.990e+00 4.050e+00 5.900e+00\n",
      "  5.840e+00 8.870e+00 8.880e+00 8.670e+00]\n",
      " [7.950e+00 7.039e+01 8.370e+00 7.200e+00 8.940e+00 8.410e+00 7.840e+00\n",
      "  6.410e+00 7.800e+00 8.030e+00 7.500e+00 8.180e+00 4.630e+00 4.580e+00\n",
      "  5.580e+00 8.350e+00 8.990e+00 8.330e+00]\n",
      " [7.230e+00 7.367e+01 8.070e+00 8.680e+00 9.220e+00 8.890e+00 7.160e+00\n",
      "  7.710e+00 8.090e+00 8.490e+00 7.720e+00 7.210e+00 5.330e+00 4.820e+00\n",
      "  5.040e+00 8.800e+00 8.990e+00 8.540e+00]\n",
      " [7.500e+00 8.153e+01 8.780e+00 8.700e+00 8.010e+00 8.610e+00 8.170e+00\n",
      "  7.250e+00 7.730e+00 7.040e+00 7.210e+00 8.010e+00 5.520e+00 5.060e+00\n",
      "  6.400e+00 8.610e+00 8.770e+00 8.130e+00]\n",
      " [8.130e+00 8.135e+01 8.720e+00 7.780e+00 8.150e+00 8.360e+00 8.650e+00\n",
      "  6.460e+00 7.140e+00 7.640e+00 8.490e+00 8.360e+00 7.190e+00 6.660e+00\n",
      "  6.450e+00 8.060e+00 8.750e+00 8.690e+00]\n",
      " [8.920e+00 8.928e+01 7.830e+00 7.200e+00 9.180e+00 8.300e+00 8.670e+00\n",
      "  7.900e+00 8.070e+00 8.390e+00 8.380e+00 7.790e+00 6.270e+00 7.660e+00\n",
      "  6.350e+00 8.690e+00 8.240e+00 8.790e+00]\n",
      " [8.940e+00 8.304e+01 7.790e+00 8.080e+00 9.150e+00 8.530e+00 8.880e+00\n",
      "  7.550e+00 8.210e+00 8.210e+00 7.420e+00 7.650e+00 6.700e+00 6.340e+00\n",
      "  6.940e+00 8.370e+00 8.780e+00 8.560e+00]\n",
      " [8.560e+00 8.935e+01 7.320e+00 7.220e+00 8.040e+00 8.610e+00 8.230e+00\n",
      "  7.730e+00 8.170e+00 7.900e+00 8.640e+00 7.950e+00 7.510e+00 6.980e+00\n",
      "  5.640e+00 8.340e+00 8.280e+00 8.770e+00]\n",
      " [8.850e+00 8.660e+01 8.520e+00 8.310e+00 9.370e+00 8.000e+00 8.070e+00\n",
      "  6.890e+00 8.000e+00 8.410e+00 7.650e+00 8.200e+00 6.770e+00 6.220e+00\n",
      "  6.920e+00 8.350e+00 8.390e+00 8.430e+00]\n",
      " [8.260e+00 8.422e+01 7.980e+00 8.060e+00 8.310e+00 8.490e+00 8.120e+00\n",
      "  7.570e+00 9.160e+00 8.020e+00 7.670e+00 8.520e+00 6.670e+00 6.950e+00\n",
      "  7.430e+00 8.140e+00 8.940e+00 8.980e+00]\n",
      " [8.840e+00 8.784e+01 7.220e+00 7.940e+00 8.340e+00 8.210e+00 8.840e+00\n",
      "  7.550e+00 9.220e+00 7.850e+00 8.810e+00 8.770e+00 7.110e+00 6.520e+00\n",
      "  8.040e+00 8.870e+00 8.080e+00 8.420e+00]\n",
      " [8.720e+00 8.601e+01 7.980e+00 8.800e+00 8.220e+00 8.360e+00 8.990e+00\n",
      "  6.930e+00 9.500e+00 8.750e+00 7.430e+00 8.220e+00 6.590e+00 7.860e+00\n",
      "  7.430e+00 8.260e+00 8.940e+00 8.510e+00]\n",
      " [8.200e+00 8.643e+01 7.930e+00 8.340e+00 8.010e+00 8.700e+00 8.670e+00\n",
      "  9.130e+00 9.230e+00 8.670e+00 8.890e+00 7.360e+00 7.670e+00 6.960e+00\n",
      "  8.360e+00 8.350e+00 8.990e+00 8.660e+00]\n",
      " [8.120e+00 8.614e+01 7.030e+00 8.510e+00 8.580e+00 9.170e+00 8.120e+00\n",
      "  8.850e+00 9.400e+00 7.520e+00 8.730e+00 8.000e+00 6.020e+00 7.230e+00\n",
      "  7.860e+00 8.170e+00 8.800e+00 8.630e+00]\n",
      " [8.670e+00 8.546e+01 7.110e+00 7.650e+00 8.210e+00 9.100e+00 8.900e+00\n",
      "  9.270e+00 9.340e+00 8.670e+00 8.880e+00 8.820e+00 7.250e+00 6.950e+00\n",
      "  7.160e+00 8.860e+00 8.930e+00 8.830e+00]\n",
      " [8.400e+00 8.744e+01 7.660e+00 8.620e+00 9.000e+00 9.350e+00 9.060e+00\n",
      "  8.700e+00 9.350e+00 7.900e+00 8.890e+00 7.130e+00 6.160e+00 6.330e+00\n",
      "  7.840e+00 8.250e+00 9.180e+00 8.600e+00]\n",
      " [8.810e+00 8.810e+01 8.020e+00 7.350e+00 8.990e+00 9.320e+00 9.270e+00\n",
      "  8.890e+00 9.150e+00 9.340e+00 7.970e+00 7.980e+00 7.080e+00 6.460e+00\n",
      "  8.940e+00 8.190e+00 9.310e+00 9.250e+00]\n",
      " [8.580e+00 8.232e+01 7.690e+00 7.740e+00 8.820e+00 9.190e+00 9.080e+00\n",
      "  9.000e+00 9.190e+00 9.290e+00 7.870e+00 7.810e+00 6.980e+00 6.520e+00\n",
      "  7.220e+00 9.070e+00 9.200e+00 9.200e+00]\n",
      " [8.020e+00 8.947e+01 9.270e+00 9.190e+00 8.900e+00 9.380e+00 9.040e+00\n",
      "  8.320e+00 9.400e+00 9.040e+00 9.020e+00 9.320e+00 7.230e+00 7.380e+00\n",
      "  7.330e+00 9.220e+00 9.440e+00 9.250e+00]\n",
      " [8.060e+00 8.813e+01 9.220e+00 9.120e+00 8.540e+00 9.180e+00 9.010e+00\n",
      "  9.200e+00 9.230e+00 9.440e+00 9.200e+00 9.400e+00 9.000e+00 8.950e+00\n",
      "  7.040e+00 9.270e+00 9.250e+00 9.270e+00]\n",
      " [8.860e+00 9.206e+01 9.210e+00 9.010e+00 8.430e+00 9.400e+00 9.090e+00\n",
      "  9.260e+00 9.490e+00 9.220e+00 9.320e+00 9.150e+00 8.060e+00 8.310e+00\n",
      "  8.390e+00 9.160e+00 9.480e+00 9.220e+00]\n",
      " [9.110e+00 9.108e+01 9.300e+00 9.310e+00 8.460e+00 9.240e+00 9.180e+00\n",
      "  8.110e+00 9.350e+00 9.260e+00 9.290e+00 9.330e+00 8.930e+00 8.020e+00\n",
      "  7.560e+00 9.110e+00 9.210e+00 9.250e+00]\n",
      " [9.110e+00 9.122e+01 9.120e+00 9.040e+00 8.290e+00 9.250e+00 9.070e+00\n",
      "  8.500e+00 9.150e+00 9.360e+00 9.290e+00 9.190e+00 8.270e+00 8.020e+00\n",
      "  7.510e+00 9.300e+00 9.090e+00 9.270e+00]\n",
      " [9.120e+00 9.091e+01 9.040e+00 9.030e+00 8.560e+00 9.310e+00 9.220e+00\n",
      "  8.010e+00 9.410e+00 9.280e+00 9.260e+00 9.250e+00 8.240e+00 8.700e+00\n",
      "  8.260e+00 9.070e+00 9.460e+00 9.090e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# regressor = SVR(kernel = 'rbf')\n",
    "# regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.195 46.92  45.757 45.795 48.651 49.373 50.64  58.687 52.72  61.832\n",
      " 61.509 62.638 60.165 62.785 63.301 63.824 64.971 62.998 63.778 62.277\n",
      " 62.689 67.283 66.319 69.224 63.513 68.836 64.982 67.15  64.265 72.757\n",
      " 76.746 83.28  83.813 81.521 83.207 81.671 83.534 86.5   83.946 79.672\n",
      " 82.146 86.006 85.743 83.343 89.263 88.766 92.34  92.535 92.003 91.986]\n"
     ]
    }
   ],
   "source": [
    "# y_pred = regressor.predict(X_test)\n",
    "# print(y_pred.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9644/722794829.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5476\u001b[0m         ):\n\u001b[0;32m   5477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5478\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8414901807038107\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "# # accuracy_score(y_test, y_pred)\n",
    "# print(regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.26748606526532\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashs\\AppData\\Local\\Temp/ipykernel_9644/3795317173.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  RFR.fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=8, random_state=0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFR = RandomForestRegressor(max_depth=10, random_state=0)\n",
    "RFR.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting the model\n",
    "import pickle\n",
    "\n",
    "pickle.dump(RFR, open('faculty.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.46193668 47.11      ]\n",
      " [46.60844479 43.97      ]\n",
      " [45.42277043 46.52      ]\n",
      " [45.39100268 49.27      ]\n",
      " [45.75045098 41.29      ]\n",
      " [45.35310598 42.05      ]\n",
      " [45.38860084 40.85      ]\n",
      " [62.48837397 57.93      ]\n",
      " [62.97055505 67.46      ]\n",
      " [62.13320631 53.43      ]\n",
      " [64.1650087  58.84      ]\n",
      " [62.51040785 65.96      ]\n",
      " [64.71458778 69.14      ]\n",
      " [62.5220964  54.48      ]\n",
      " [62.38959641 68.82      ]\n",
      " [61.94979005 57.16      ]\n",
      " [62.47236129 72.22      ]\n",
      " [62.39839945 55.41      ]\n",
      " [61.48587734 64.9       ]\n",
      " [62.80215939 62.66      ]\n",
      " [61.87044183 58.61      ]\n",
      " [61.71270103 56.46      ]\n",
      " [62.00597509 67.8       ]\n",
      " [62.91619055 53.7       ]\n",
      " [62.5027739  57.98      ]\n",
      " [61.93616336 62.08      ]\n",
      " [62.65914202 74.64      ]\n",
      " [62.68044963 67.66      ]\n",
      " [63.56832349 65.46      ]\n",
      " [81.78786275 78.69      ]\n",
      " [82.9924625  80.41      ]\n",
      " [82.76924251 79.92      ]\n",
      " [82.42144845 79.32      ]\n",
      " [83.17271499 82.55      ]\n",
      " [82.15522835 76.69      ]\n",
      " [82.69380692 89.78      ]\n",
      " [82.13650585 78.79      ]\n",
      " [83.31675983 79.39      ]\n",
      " [82.86196637 80.79      ]\n",
      " [82.82741161 85.47      ]\n",
      " [81.92322413 83.37      ]\n",
      " [82.5593955  75.75      ]\n",
      " [82.01913262 81.21      ]\n",
      " [82.11471868 89.7       ]\n",
      " [92.59897359 94.39      ]\n",
      " [92.46056097 94.97      ]\n",
      " [93.09049904 93.3       ]\n",
      " [92.10163304 94.89      ]\n",
      " [92.9477507  93.8       ]\n",
      " [92.69312264 92.44      ]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = RFR.predict(X_test)\n",
    "y_actual = np.array(y_test)\n",
    "\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_actual.reshape(len(y_actual), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9092104636925843"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "RFR.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9056638670740198"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy\n",
    "RFR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.835087371710364\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing 2 faculty scores - in same slot course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Score of Faculty #47: 92.1016330398494 \n",
      "Predicted Score of Faculty #17: 62.39839944926425\n",
      "Faculty #47 is better than Faculty #17\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted Score of Faculty #47:\", y_pred[47], \"\\nPredicted Score of Faculty #17:\", y_pred[17], sep=\" \")\n",
    "if y_pred[47] > y_pred[17]:\n",
    "    print(\"Faculty #47 is better than Faculty #17\")\n",
    "else:\n",
    "    print(\"Faculty #17 is better than Faculty #47\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
