{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory Only Course"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting grade from predicted externals marks (FAT) based on Internals (CAT1, CAT2, DA1, DA2, DA3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "RFR = RandomForestRegressor(max_depth=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAT1</th>\n",
       "      <th>CAT2</th>\n",
       "      <th>DA1</th>\n",
       "      <th>DA2</th>\n",
       "      <th>DA3</th>\n",
       "      <th>FAT</th>\n",
       "      <th>LAB1</th>\n",
       "      <th>LAB2</th>\n",
       "      <th>LAB3</th>\n",
       "      <th>LAB4</th>\n",
       "      <th>LAB5</th>\n",
       "      <th>LAB6</th>\n",
       "      <th>LFAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAT1  CAT2  DA1  DA2  DA3  FAT  LAB1  LAB2  LAB3  LAB4  LAB5  LAB6  LFAT\n",
       "0     8    10    9    7   10   30     9     9    10     9     8     7    31\n",
       "1    10     8    8    7    7   33     8     8     7     8    10    10    32\n",
       "2     9     5    9   10    9   38    10     7     9     7    10     7    30\n",
       "3     8     5    7    9    7   55     7     9     7    10    10    10    30\n",
       "4     6    10    9    9    9   53     7     8     7     9     9     7    31"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataset\n",
    "student_data = pd.read_csv(\"./thelab.csv\")\n",
    "# student_data = student_data.sample(frac=1)\n",
    "\n",
    "# taking input for class of 70 - for realistic emulation of class grades distribution\n",
    "test_data = pd.read_csv(\"testInternals.csv\")\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 5) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# extract the required output and input variables\n",
    "X_train = student_data[['CAT1', 'CAT2', \"DA1\", \"DA2\", \"DA3\"]]\n",
    "y_train = student_data['FAT']\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "RFR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.2459474  31.        ]\n",
      " [50.04739126 39.        ]\n",
      " [44.47216076 33.        ]\n",
      " [47.68288591 47.        ]\n",
      " [48.15624305 41.        ]\n",
      " [47.31836296 41.        ]\n",
      " [48.87624401 53.        ]\n",
      " [67.51528112 77.        ]\n",
      " [66.79867852 59.        ]\n",
      " [68.12824376 69.        ]\n",
      " [67.88313491 64.        ]\n",
      " [69.19290119 61.        ]\n",
      " [67.5276304  69.        ]\n",
      " [67.46968479 73.        ]\n",
      " [67.35954426 74.        ]\n",
      " [67.81245174 60.        ]\n",
      " [67.28964421 70.        ]\n",
      " [67.24517883 60.        ]\n",
      " [67.46706229 68.        ]\n",
      " [67.17070857 75.        ]\n",
      " [68.81493533 66.        ]\n",
      " [67.26267107 67.        ]\n",
      " [67.6935752  60.        ]\n",
      " [67.49462489 61.        ]\n",
      " [67.28464994 67.        ]\n",
      " [67.45426033 79.        ]\n",
      " [67.52494427 70.        ]\n",
      " [67.39685535 78.        ]\n",
      " [68.71366794 72.        ]\n",
      " [67.36382104 68.        ]\n",
      " [67.64124998 74.        ]\n",
      " [67.06430854 70.        ]\n",
      " [67.50902926 57.        ]\n",
      " [67.37239977 59.        ]\n",
      " [67.52108791 58.        ]\n",
      " [67.61449462 58.        ]\n",
      " [67.93102516 59.        ]\n",
      " [67.379466   66.        ]\n",
      " [67.1556874  59.        ]\n",
      " [65.82900129 76.        ]\n",
      " [67.61420579 59.        ]\n",
      " [67.1526702  57.        ]\n",
      " [67.28538094 63.        ]\n",
      " [66.55384201 73.        ]\n",
      " [67.06806646 57.        ]\n",
      " [67.93439085 76.        ]\n",
      " [68.55027083 66.        ]\n",
      " [67.19183073 78.        ]\n",
      " [66.92244331 77.        ]\n",
      " [67.20229983 66.        ]\n",
      " [67.06823047 65.        ]\n",
      " [67.62966326 66.        ]\n",
      " [66.84048406 59.        ]\n",
      " [66.8585185  65.        ]\n",
      " [68.90475272 69.        ]\n",
      " [66.99379595 63.        ]\n",
      " [67.13046032 77.        ]\n",
      " [67.01519011 70.        ]\n",
      " [67.5374794  63.        ]\n",
      " [86.86955122 97.        ]\n",
      " [87.90119721 83.        ]\n",
      " [89.38105206 91.        ]\n",
      " [88.29580607 81.        ]\n",
      " [88.47575015 87.        ]\n",
      " [89.27651074 82.        ]\n",
      " [89.03553044 90.        ]\n",
      " [87.50291175 84.        ]\n",
      " [87.84134886 93.        ]\n",
      " [86.98282995 91.        ]\n",
      " [87.6210599  87.        ]]\n"
     ]
    }
   ],
   "source": [
    "# computing the predictions using testing data and comparing the outputs\n",
    "\n",
    "X_test = test_data[['CAT1', 'CAT2', \"DA1\", \"DA2\", \"DA3\"]]\n",
    "y_test = test_data['FAT']\n",
    "\n",
    "y_pred_fat = RFR.predict(X_test)\n",
    "y_actual = np.array(y_test)\n",
    "\n",
    "print(np.concatenate((y_pred_fat.reshape(len(y_pred_fat), 1), y_actual.reshape(len(y_actual), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7244464197268923"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "RFR.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7409613976760021"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing accuracy\n",
    "RFR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.8 27.0 29.4 29.2 30.9 31.5 30.1 37.8 32.6 33.6 36.6 34.7 35.5 36.6\n",
      " 37.2 36.2 34.8 42.2 38.4 44.7 42.6 43.2 43.2 40.8 39.7 42.1 39.5 42.7\n",
      " 41.0 41.0 41.2 38.2 40.4 37.2 42.1 41.3 38.5 38.5 47.0 46.3 45.2 47.3\n",
      " 44.6 48.5 52.4 47.6 49.8 47.3 46.1 45.7 49.4 46.3 47.7 47.2 47.3 49.0\n",
      " 45.2 43.1 50.9 49.8 49.4 53.6 50.2 54.9 52.2 46.6 51.0 49.1 52.4 54.7]\n"
     ]
    }
   ],
   "source": [
    "internal = np.empty(len(y_pred_fat), dtype=object)\n",
    "counter = 0\n",
    "\n",
    "for i in X_test.index:\n",
    "  internal[counter]=round((15/50)*X_test['CAT1'][i],2) + round((15/50)*X_test['CAT2'][i],2) + X_test['DA1'][i] + X_test['DA2'][i] + X_test['DA3'][i]\n",
    "  counter += 1\n",
    "\n",
    "print(internal)\n",
    "totPred = internal + (0.4)*y_pred_fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49.898378961347746 47.01895650456436 47.18886430456307 48.27315436567383\n",
      " 50.16249721854988 50.42734518419559 49.65049760267161 64.80611244834303\n",
      " 59.319471409293726 60.851297502581616 63.75325396334941 62.37716047554703\n",
      " 62.511052160526596 63.58787391661127 64.14381770429692 63.32498069512399\n",
      " 61.71585768591353 69.09807153382977 65.38682491781886 71.56828342799388\n",
      " 70.12597413365683 70.10506842742214 70.27743007945912 67.79784995429759\n",
      " 66.61385997531539 69.08170413149108 66.50997770990098 69.65874214034257\n",
      " 68.48546717441651 67.945528415599 68.25649999022272 65.02572341506074\n",
      " 67.40361170549507 64.14895990957574 69.10843516408009 68.34579784767168\n",
      " 65.67241006464096 65.45178639967187 73.86227496000481 72.6316005165178\n",
      " 72.24568231508606 74.16106808167949 71.51415237555595 75.12153680278652\n",
      " 79.22722658536432 74.77375634027885 77.22010833368398 74.17673229374162\n",
      " 72.86897732318567 72.58091993237348 76.2272921894821 73.35186530335892\n",
      " 74.43619362481726 73.94340740191156 74.86190108989824 75.79751837804852\n",
      " 72.0521841283884 69.9060760440019 77.91499175816664 84.54782048684082\n",
      " 84.56047888558878 89.35242082201108 85.51832242900099 90.2903000599508\n",
      " 87.91060429609891 82.21421217783981 86.00116469958901 84.2365395448754\n",
      " 87.1931319780339 89.74842395817736]\n"
     ]
    }
   ],
   "source": [
    "print(totPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SD: 10.277043384117269\n",
      "Mean: 70.07896376767796\n",
      "['E' 'F' 'F' 'F' 'E' 'E' 'E' 'C' 'D' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'C' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'C' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'A' 'B' 'A' 'B' 'B' 'B' 'A' 'B' 'B' 'B'\n",
      " 'B' 'A' 'B' 'B' 'A' 'A' 'A' 'S' 'S' 'S' 'S' 'A' 'S' 'A' 'S' 'S']\n",
      "(array(['A', 'B', 'C', 'D', 'E', 'F', 'S'], dtype=object), array([ 9, 36, 10,  1,  4,  3,  7], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# computing grades based on y_pred\n",
    "grade = np.empty(len(y_pred_fat), dtype = object)\n",
    "Mean=np.mean(totPred)\n",
    "sd=np.std(totPred)\n",
    "print(\"SD:\", sd)\n",
    "print(\"Mean:\", Mean)\n",
    "\n",
    "for i in range(0,len(totPred)):\n",
    "  if internal[i] < 30 and y_pred_fat[i] < 40:\n",
    "    grade[i] = 'F'\n",
    "  else:\n",
    "    if totPred[i]>= Mean + 1.5*sd:\n",
    "      grade[i]='S'\n",
    "    elif totPred[i]>=Mean + 0.5*sd and totPred[i] < Mean + 1.5*sd:\n",
    "      grade[i]='A'\n",
    "    elif totPred[i] >= Mean - 0.5*sd and totPred[i] < Mean + 0.5*sd:\n",
    "      grade[i]='B'\n",
    "    elif totPred[i]>= Mean - 1.0*sd and totPred[i] < Mean - 0.5*sd:\n",
    "      grade[i]='C'\n",
    "    elif totPred[i] >= Mean - 1.5*sd and totPred[i] < Mean - 1.0*sd:\n",
    "      grade[i]='D'\n",
    "    elif totPred[i] >= Mean - 2.0*sd and totPred[i] < Mean - 1.5*sd:\n",
    "      grade[i]='E'\n",
    "    elif totPred[i] < Mean - 2.0*sd:\n",
    "      grade[i]='F'\n",
    "\n",
    "print(grade)\n",
    "print(np.unique(grade, return_counts=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory + Lab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Grade using internals (DA1, DA2, DA3) and Lab Marks (Internals + Predicted Lab Fat marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAT1</th>\n",
       "      <th>CAT2</th>\n",
       "      <th>DA1</th>\n",
       "      <th>DA2</th>\n",
       "      <th>DA3</th>\n",
       "      <th>FAT</th>\n",
       "      <th>LAB1</th>\n",
       "      <th>LAB2</th>\n",
       "      <th>LAB3</th>\n",
       "      <th>LAB4</th>\n",
       "      <th>LAB5</th>\n",
       "      <th>LAB6</th>\n",
       "      <th>LFAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAT1  CAT2  DA1  DA2  DA3  FAT  LAB1  LAB2  LAB3  LAB4  LAB5  LAB6  LFAT\n",
       "0     7    10    9    7    7   34     8     7     7     9     8     7    32\n",
       "1     7     8    7   10    9   30     8     9     9    10    10    10    32\n",
       "2     8    10    7    8    8   35     8    10    10     7    10    10    32\n",
       "3     8     5    8    9    9   41     9     7     7    10    10     8    31\n",
       "4     5     5    7    8    8   40     7    10     7     8     8     9    32"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataset\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "theory_lab = pd.read_csv(\"./thelab.csv\")\n",
    "# student_data = student_data.sample(frac=1)\n",
    "\n",
    "# taking input for class of 70 - for realistic emulation of class grades distribution\n",
    "theory_lab_test = pd.read_csv(\"./thelabtest.csv\")\n",
    "theory_lab_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 6) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# extract the required output and input variables\n",
    "X_train= theory_lab[[\"LAB1\", \"LAB2\", \"LAB3\", \"LAB4\", \"LAB5\", \"LAB6\"]]\n",
    "y_train = theory_lab[\"LFAT\"]\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "RFR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34.59470476 32.        ]\n",
      " [35.10400167 32.        ]\n",
      " [34.79433108 32.        ]\n",
      " [34.94525229 31.        ]\n",
      " [34.39782332 32.        ]\n",
      " [34.96764233 31.        ]\n",
      " [34.69237379 32.        ]\n",
      " [34.93831162 32.        ]\n",
      " [34.97627325 32.        ]\n",
      " [35.24902197 30.        ]\n",
      " [35.67861924 31.        ]\n",
      " [35.06148419 30.        ]\n",
      " [35.37774674 31.        ]\n",
      " [35.20068036 30.        ]\n",
      " [34.97343094 35.        ]\n",
      " [34.59544572 36.        ]\n",
      " [35.12339374 36.        ]\n",
      " [35.1369547  33.        ]\n",
      " [34.37501756 36.        ]\n",
      " [35.12994006 37.        ]\n",
      " [34.02150646 35.        ]\n",
      " [34.90563544 35.        ]\n",
      " [35.63017974 37.        ]\n",
      " [35.44187098 36.        ]\n",
      " [34.76453905 37.        ]\n",
      " [34.85306609 36.        ]\n",
      " [34.61827372 37.        ]\n",
      " [35.15685455 35.        ]\n",
      " [34.98436896 34.        ]\n",
      " [34.83040171 37.        ]\n",
      " [34.99832837 34.        ]\n",
      " [35.3016673  33.        ]\n",
      " [35.12175865 36.        ]\n",
      " [35.1399976  35.        ]\n",
      " [35.10181845 35.        ]\n",
      " [35.24227936 33.        ]\n",
      " [35.71370038 36.        ]\n",
      " [34.66159037 34.        ]\n",
      " [34.6303973  35.        ]\n",
      " [34.90583097 34.        ]\n",
      " [35.14171932 34.        ]\n",
      " [34.84037415 35.        ]\n",
      " [34.5518296  35.        ]\n",
      " [34.54912254 35.        ]\n",
      " [35.2368865  33.        ]\n",
      " [34.68675093 33.        ]\n",
      " [34.64320447 37.        ]\n",
      " [34.90259081 33.        ]\n",
      " [35.20052892 37.        ]\n",
      " [35.28614301 37.        ]\n",
      " [34.98637857 34.        ]\n",
      " [35.16416789 37.        ]\n",
      " [34.5836791  33.        ]\n",
      " [34.82604833 34.        ]\n",
      " [35.18843191 33.        ]\n",
      " [35.18559683 37.        ]\n",
      " [34.94343534 38.        ]\n",
      " [35.41902752 39.        ]\n",
      " [35.23798516 38.        ]\n",
      " [35.02362525 40.        ]\n",
      " [34.95361704 38.        ]\n",
      " [35.14816704 38.        ]\n",
      " [35.1241127  40.        ]\n",
      " [35.30180157 40.        ]\n",
      " [35.20691796 38.        ]\n",
      " [35.19381914 40.        ]\n",
      " [34.8879494  39.        ]\n",
      " [35.76249749 39.        ]\n",
      " [35.17156782 40.        ]\n",
      " [34.66179604 38.        ]]\n"
     ]
    }
   ],
   "source": [
    "# computing the predictions using testing data and comparing the outputs\n",
    "\n",
    "X_test= theory_lab_test[[\"LAB1\", \"LAB2\", \"LAB3\", \"LAB4\", \"LAB5\", \"LAB6\"]]\n",
    "y_test = theory_lab_test[\"LFAT\"]\n",
    "\n",
    "y_pred_lab = RFR.predict(X_test)\n",
    "y_actual = np.array(y_test)\n",
    "\n",
    "print(np.concatenate((y_pred_lab.reshape(len(y_pred_lab), 1), y_actual.reshape(len(y_actual), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0714087756932793\n"
     ]
    }
   ],
   "source": [
    "# training accuracy\n",
    "print(RFR.score(X_train, y_train))\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6892556761973814\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(y_actual, y_pred_lab)))\n",
    "# print(r2_score(y_actual, y_pred_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015658708074686944\n"
     ]
    }
   ],
   "source": [
    "print(RFR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1df19a4d640>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(np.arange(0,len(y_train)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'F' 'F' 'F' 'E' 'E' 'F' 'B' 'D' 'C' 'C' 'C' 'C' 'B' 'C' 'C' 'C' 'B'\n",
      " 'C' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'C' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'A' 'B' 'B' 'A' 'B' 'A' 'B' 'B' 'B' 'A' 'B' 'B' 'B'\n",
      " 'B' 'A' 'B' 'B' 'A' 'A' 'A' 'S' 'S' 'S' 'S' 'A' 'S' 'A' 'S' 'S']\n",
      "(array(['A', 'B', 'C', 'D', 'E', 'F', 'S'], dtype=object), array([10, 36,  9,  1,  2,  5,  7], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Theory+Lab\n",
    "\n",
    "# thetot=internal+(0.4*fat)\n",
    "labtot= X_test.sum(axis=1) + y_pred_lab\n",
    "tot=(0.75*totPred)+(0.25*labtot)\n",
    "Mean=np.mean(tot)\n",
    "sd=np.std(tot)\n",
    "grade = np.empty(len(y_pred_lab), dtype=object)\n",
    "for i in range(0,len(y_pred_lab)):\n",
    "  if y_pred_fat[i]<40 or tot[i]<50:\n",
    "    grade[i]='F'\n",
    "  else:\n",
    "    if tot[i]>= Mean + 1.5*sd:\n",
    "      grade[i]='S'\n",
    "    elif tot[i]>=Mean + 0.5*sd and tot[i] < Mean + 1.5*sd:\n",
    "      grade[i]='A'\n",
    "    elif tot[i] >= Mean - 0.5*sd and tot[i] < Mean + 0.5*sd:\n",
    "      grade[i]='B'\n",
    "    elif tot[i ]>= Mean - 1.0*sd and tot[i] < Mean - 0.5*sd:\n",
    "      grade[i]='C'\n",
    "    elif tot[i] >= Mean - 1.5*sd and tot[i] < Mean - 1.0*sd:\n",
    "      grade[i]='D'\n",
    "    elif tot[i] >= Mean - 2.0*sd and tot[i] < Mean - 1.5*sd:\n",
    "      grade[i]='E'\n",
    "    elif tot[i] < Mean - 2.0*sd:\n",
    "      grade[i]='F'\n",
    "\n",
    "print(grade)\n",
    "print(np.unique(grade, return_counts=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory + Lab + J Comp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Grade using internals (DA1, DA2, DA3) and Lab Marks (Internals + Predicted Lab Fat marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAT1</th>\n",
       "      <th>CAT2</th>\n",
       "      <th>DA1</th>\n",
       "      <th>DA2</th>\n",
       "      <th>DA3</th>\n",
       "      <th>FAT</th>\n",
       "      <th>LAB1</th>\n",
       "      <th>LAB2</th>\n",
       "      <th>LAB3</th>\n",
       "      <th>LAB4</th>\n",
       "      <th>LAB5</th>\n",
       "      <th>LAB6</th>\n",
       "      <th>LFAT</th>\n",
       "      <th>REV1</th>\n",
       "      <th>REV2</th>\n",
       "      <th>REV3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAT1  CAT2  DA1  DA2  DA3  FAT  LAB1  LAB2  LAB3  LAB4  LAB5  LAB6  LFAT  \\\n",
       "0    10     8    9    9   10   30     7     8     9     8     9     8    32   \n",
       "1     5     5   10    7    8   30    10     9     9     8     8     7    30   \n",
       "2     8    10    9    7    8   38     8    10     7     7     9     9    31   \n",
       "3     7    10    9    9   10   45     7    10     9     8     7     8    32   \n",
       "4     8     7    8   10    8   50    10    10     8     7     7     7    31   \n",
       "\n",
       "   REV1  REV2  REV3  \n",
       "0    20    27    45  \n",
       "1    17    26    43  \n",
       "2    19    28    43  \n",
       "3    18    30    46  \n",
       "4    20    27    43  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the dataset\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "theory_lab_j = pd.read_csv(\"./TLJ.csv\")\n",
    "# student_data = student_data.sample(frac=1)\n",
    "\n",
    "# taking input for class of 70 - for realistic emulation of class grades distribution\n",
    "theory_lab_j_test = pd.read_csv(\"./TLJtest.csv\")\n",
    "theory_lab_j_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) (2000,)\n"
     ]
    }
   ],
   "source": [
    "# extract the required output and input variables\n",
    "X_train= theory_lab_j[[\"REV1\", \"REV2\"]]\n",
    "y_train = theory_lab_j[\"REV3\"]\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=5, random_state=0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model\n",
    "RFR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[46.99437631 45.        ]\n",
      " [47.13008905 43.        ]\n",
      " [47.29890057 43.        ]\n",
      " [47.12639243 46.        ]\n",
      " [46.99437631 43.        ]\n",
      " [46.99437631 44.        ]\n",
      " [47.13992955 44.        ]\n",
      " [46.99437631 48.        ]\n",
      " [47.36632732 47.        ]\n",
      " [46.94432586 48.        ]\n",
      " [47.43766657 48.        ]\n",
      " [47.27567769 48.        ]\n",
      " [47.27962489 47.        ]\n",
      " [47.15141732 47.        ]\n",
      " [47.09022779 47.        ]\n",
      " [47.13058128 47.        ]\n",
      " [47.10353893 48.        ]\n",
      " [46.99437631 48.        ]\n",
      " [47.19147352 48.        ]\n",
      " [47.50306206 47.        ]\n",
      " [47.2438549  48.        ]\n",
      " [47.11359799 47.        ]\n",
      " [47.13058128 47.        ]\n",
      " [47.27567769 48.        ]\n",
      " [47.07278924 48.        ]\n",
      " [47.18013998 47.        ]\n",
      " [47.2476624  48.        ]\n",
      " [47.38749321 48.        ]\n",
      " [47.27567769 48.        ]\n",
      " [47.13992955 48.        ]\n",
      " [47.43766657 48.        ]\n",
      " [47.27567769 48.        ]\n",
      " [47.12072342 47.        ]\n",
      " [47.31218351 47.        ]\n",
      " [47.28454811 48.        ]\n",
      " [47.27283142 48.        ]\n",
      " [47.13992955 48.        ]\n",
      " [47.18013998 47.        ]\n",
      " [47.27567769 47.        ]\n",
      " [47.29890057 48.        ]\n",
      " [47.15141732 47.        ]\n",
      " [47.2441925  48.        ]\n",
      " [47.16055617 47.        ]\n",
      " [47.12639243 48.        ]\n",
      " [47.2871077  48.        ]\n",
      " [47.28454811 47.        ]\n",
      " [47.27962489 47.        ]\n",
      " [47.2441925  48.        ]\n",
      " [47.17975285 48.        ]\n",
      " [47.17678137 48.        ]\n",
      " [47.03513851 47.        ]\n",
      " [47.05633837 47.        ]\n",
      " [47.14499088 47.        ]\n",
      " [47.2438549  47.        ]\n",
      " [47.13058128 48.        ]\n",
      " [47.19147352 47.        ]\n",
      " [46.99437631 47.        ]\n",
      " [47.24744008 48.        ]\n",
      " [47.11276396 47.        ]\n",
      " [47.18013998 48.        ]\n",
      " [47.14499088 48.        ]\n",
      " [47.33517649 47.        ]\n",
      " [47.38749321 48.        ]\n",
      " [47.2871077  48.        ]\n",
      " [47.27567769 48.        ]\n",
      " [47.2476624  48.        ]\n",
      " [47.29890057 48.        ]\n",
      " [47.17975285 47.        ]\n",
      " [47.12072342 48.        ]\n",
      " [47.2193686  47.        ]]\n"
     ]
    }
   ],
   "source": [
    "# computing the predictions using testing data and comparing the outputs\n",
    "\n",
    "X_test= theory_lab_j_test[[\"REV1\", \"REV2\"]]\n",
    "y_test = theory_lab_j_test[\"REV3\"]\n",
    "\n",
    "y_pred_J = RFR.predict(X_test)\n",
    "y_actual = np.array(y_test)\n",
    "\n",
    "print(np.concatenate((y_pred_J.reshape(len(y_pred_J), 1), y_actual.reshape(len(y_actual), 1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014715164206335896\n"
     ]
    }
   ],
   "source": [
    "# training accuracy\n",
    "print(RFR.score(X_train, y_train))\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1912452618574385\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(mean_squared_error(y_actual, y_pred_J)))\n",
    "# print(r2_score(y_actual, y_pred_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042887840041403\n"
     ]
    }
   ],
   "source": [
    "print(RFR.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1df1ab95430>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(np.arange(0,len(y_train)), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "print(len(y_pred_J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'F' 'E' 'E' 'E' 'E' 'F' 'B' 'D' 'C' 'C' 'C' 'C' 'B' 'C' 'C' 'C' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'C' 'B' 'B' 'B' 'B' 'B' 'B' 'C' 'B' 'B'\n",
      " 'B' 'B' 'A' 'A' 'B' 'A' 'B' 'B' 'A' 'A' 'B' 'B' 'B' 'B' 'A' 'B' 'B' 'B'\n",
      " 'B' 'A' 'B' 'B' 'B' 'S' 'A' 'S' 'A' 'S' 'S' 'A' 'S' 'A' 'S' 'S']\n",
      "(array(['A', 'B', 'C', 'D', 'E', 'F', 'S'], dtype=object), array([11, 35,  9,  1,  4,  3,  7], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "#Theory+Lab+J\n",
    "\n",
    "# thetot=internal+(0.4*fat)\n",
    "# labtot= X_test.sum(axis=1) + y_pred_lab\n",
    "jcomp = X_test.sum(axis=1) + y_pred_J\n",
    "tot=(0.5*totPred)+(0.25*labtot)+(0.25*jcomp)\n",
    "Mean=np.mean(tot)\n",
    "sd=np.std(tot)\n",
    "grade = np.empty(len(y_pred_J), dtype=object)\n",
    "for i in range(0,len(y_pred_J)):\n",
    "  if y_pred_fat[i]<40 or tot[i]<50:\n",
    "    grade[i]='F'\n",
    "  else:\n",
    "    if tot[i]>= Mean + 1.5*sd:\n",
    "      grade[i]='S'\n",
    "    elif tot[i]>=Mean + 0.5*sd and tot[i] < Mean + 1.5*sd:\n",
    "      grade[i]='A'\n",
    "    elif tot[i] >= Mean - 0.5*sd and tot[i] < Mean + 0.5*sd:\n",
    "      grade[i]='B'\n",
    "    elif tot[i ]>= Mean - 1.0*sd and tot[i] < Mean - 0.5*sd:\n",
    "      grade[i]='C'\n",
    "    elif tot[i] >= Mean - 1.5*sd and tot[i] < Mean - 1.0*sd:\n",
    "      grade[i]='D'\n",
    "    elif tot[i] >= Mean - 2.0*sd and tot[i] < Mean - 1.5*sd:\n",
    "      grade[i]='E'\n",
    "    elif tot[i] < Mean - 2.0*sd:\n",
    "      grade[i]='F'\n",
    "\n",
    "print(grade)\n",
    "print(np.unique(grade, return_counts=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
